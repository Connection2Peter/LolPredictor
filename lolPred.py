# -*- coding: utf-8 -*-
"""LolPred.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aRVV9RPO4kjZf4WpjOp_Gc2z2HJYr_8C
"""

!wget https://raw.githubusercontent.com/Connection2Peter/LolPredictor/master/db/2022-09-02_19-27-42_Ironmin136.csv

import csv
import numpy as np

pathData = "2022-09-02_19-27-42_Ironmin136.csv"
rawMatches = []

with open(pathData, encoding='utf-8-sig', newline='') as csvfile:
  rows = csv.reader(csvfile)

  for row in rows:
    rawMatches.append(row)

print(np.shape(rawMatches))

raw_X_train, raw_y_train = [], []

for i in rawMatches:
  raw_X_train.append([float(j) for j in i[1:]])
  raw_y_train.append(int(float(i[0]))-1)

raw_X_train = np.array(raw_X_train)
raw_y_train = np.array(raw_y_train)

print(raw_X_train.shape, raw_y_train.shape)

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(raw_X_train, raw_y_train, train_size= 0.8, random_state=87)

X_train.shape, X_test.shape, y_train.shape, y_test.shape

from sklearn.tree import ExtraTreeClassifier
from sklearn.metrics import accuracy_score
from sklearn.mixture import GaussianMixture
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier, NearestCentroid, RadiusNeighborsClassifier
from sklearn.naive_bayes import GaussianNB, BernoulliNB
from sklearn.linear_model import SGDClassifier, LogisticRegressionCV, RidgeClassifier, RidgeClassifierCV
from sklearn.neural_network import MLPClassifier
from sklearn.semi_supervised import LabelPropagation, LabelSpreading
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis

# 0.6233766233766234 model = GaussianNB()
# 0.5714285714285714 model = SGDClassifier()
# 0.5584415584415584 model = RandomForestClassifier(n_jobs=-1, random_state=136, n_estimators=500)
# 0.5454545454545454 model = ExtraTreeClassifier()
# 0.5194805194805194 model = LabelPropagation()
model = RidgeClassifierCV()
model.fit(X_train, y_train)

accuracy_score(y_test, model.predict(X_test))

"""**### 一般神經網路**"""

from keras.utils.np_utils import to_categorical
from sklearn.model_selection import train_test_split

raw_y_train = to_categorical(raw_y_train)

X_train, X_test, y_train, y_test = train_test_split(raw_X_train, raw_y_train, train_size= 0.8, random_state=87)

print(np.shape(X_train))
print(np.shape(X_test))
print(np.shape(y_train))
print(np.shape(y_test))

import tensorflow as tf
from tensorflow.keras.models import Model, load_model
from tensorflow.keras import layers
from tensorflow.keras import optimizers

model = tf.keras.models.Sequential(name = "Model")

model.add(tf.keras.Input(shape=(len(X_train[0]),)))
model.add(layers.Dense(128,"relu"))
model.add(layers.Dense(64,"relu"))
model.add(layers.Dense(32,"relu"))
model.add(layers.Dense(2,"softmax"))

model.summary()

model.compile(
  optimizer='adam',
  loss=tf.keras.losses.CategoricalCrossentropy(),
  metrics=['acc']
)

model.fit(X_train, y_train, epochs=100, batch_size=20, validation_split= 0.2)

model.evaluate(X_test, y_test)